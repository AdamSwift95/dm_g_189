{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a90ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import missingno as msn\n",
    "import dexplot as dxp\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98022b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fce8706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train=pd.read_csv(\"../training_set_VU_DM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b533ecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropping columns with high nulls\n",
    "\n",
    "to_drop= ['comp1_rate',\n",
    "'comp1_inv',\n",
    "'comp1_rate_percent_diff',\n",
    "'comp2_rate',\n",
    "'comp2_inv',\n",
    "'comp2_rate_percent_diff',\n",
    "'comp3_rate',\n",
    "'comp3_inv',\n",
    "'comp3_rate_percent_diff',\n",
    "'comp4_rate',\n",
    "'comp4_inv',\n",
    "'comp4_rate_percent_diff',\n",
    "'comp5_rate',\n",
    "'comp5_inv',\n",
    "'comp5_rate_percent_diff',\n",
    "'comp6_rate',\n",
    "'comp6_inv',\n",
    "'comp6_rate_percent_diff',\n",
    "'comp7_rate',\n",
    "'comp7_inv',\n",
    "'comp7_rate_percent_diff',\n",
    "'comp8_rate',\n",
    "'comp8_inv',\n",
    "'comp8_rate_percent_diff']\n",
    "\n",
    "\n",
    "#creating dependant variable \n",
    "\n",
    "conditions = [\n",
    "    (train['click_bool']> 0)\n",
    "]\n",
    "\n",
    "choices = [1]\n",
    "train['outcome'] = np.select(conditions, choices, default=0)\n",
    "\n",
    "train = train.drop(to_drop,  axis=1)#.sample(frac=0.2, replace=True, random_state=1)\n",
    "\n",
    "#filtering out price outliers \n",
    "train = train[train.price_usd < 3001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a4fc7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>...</th>\n",
       "      <th>srch_children_count</th>\n",
       "      <th>srch_room_count</th>\n",
       "      <th>srch_saturday_night_bool</th>\n",
       "      <th>srch_query_affinity_score</th>\n",
       "      <th>orig_destination_distance</th>\n",
       "      <th>random_bool</th>\n",
       "      <th>click_bool</th>\n",
       "      <th>gross_bookings_usd</th>\n",
       "      <th>booking_bool</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>10404</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>21315</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>27348</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>29604</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id            date_time  site_id  visitor_location_country_id  \\\n",
       "0        1  2013-04-04 08:32:15       12                          187   \n",
       "1        1  2013-04-04 08:32:15       12                          187   \n",
       "2        1  2013-04-04 08:32:15       12                          187   \n",
       "3        1  2013-04-04 08:32:15       12                          187   \n",
       "4        1  2013-04-04 08:32:15       12                          187   \n",
       "\n",
       "   visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id  prop_id  \\\n",
       "0                      NaN                   NaN              219      893   \n",
       "1                      NaN                   NaN              219    10404   \n",
       "2                      NaN                   NaN              219    21315   \n",
       "3                      NaN                   NaN              219    27348   \n",
       "4                      NaN                   NaN              219    29604   \n",
       "\n",
       "   prop_starrating  prop_review_score  ...  srch_children_count  \\\n",
       "0                3                3.5  ...                    0   \n",
       "1                4                4.0  ...                    0   \n",
       "2                3                4.5  ...                    0   \n",
       "3                2                4.0  ...                    0   \n",
       "4                4                3.5  ...                    0   \n",
       "\n",
       "   srch_room_count  srch_saturday_night_bool  srch_query_affinity_score  \\\n",
       "0                1                         1                        NaN   \n",
       "1                1                         1                        NaN   \n",
       "2                1                         1                        NaN   \n",
       "3                1                         1                        NaN   \n",
       "4                1                         1                        NaN   \n",
       "\n",
       "   orig_destination_distance  random_bool  click_bool  gross_bookings_usd  \\\n",
       "0                        NaN            1           0                 NaN   \n",
       "1                        NaN            1           0                 NaN   \n",
       "2                        NaN            1           0                 NaN   \n",
       "3                        NaN            1           0                 NaN   \n",
       "4                        NaN            1           0                 NaN   \n",
       "\n",
       "   booking_bool  outcome  \n",
       "0             0        0  \n",
       "1             0        0  \n",
       "2             0        0  \n",
       "3             0        0  \n",
       "4             0        0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head() # 30 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80722bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['id_with_booking'] = train.groupby('srch_id')['booking_bool'].transform('sum')\n",
    "# print(np.unique(train['id_with_booking']))\n",
    "\n",
    "# train2 = train.drop(train[(train['id_with_booking'] == 0)].index)\n",
    "# train2 = train2.drop(['id_with_booking'],  axis=1)#.sample(frac=0.2, replace=True, random_state=1)\n",
    "\n",
    "# train = train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c2ec907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-8a4ad4be83d5>:5: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  train[\"week_of_year\"] = train[\"date_time\"].dt.week\n"
     ]
    }
   ],
   "source": [
    "## creating time related features\n",
    "    \n",
    "train['date_time'] = pd.to_datetime(train['date_time'], errors='coerce')\n",
    "train[\"weekday\"] = train[\"date_time\"].dt.weekday\n",
    "train[\"week_of_year\"] = train[\"date_time\"].dt.week\n",
    "train[\"month\"] = train[\"date_time\"].dt.month\n",
    "train[\"hour\"] = train[\"date_time\"].dt.hour\n",
    "## total time elapsed - allows model to learn continous trend over time to a degree\n",
    "train[\"time_epoch\"] = train[\"date_time\"].astype('int64')//1e9\n",
    "train.loc[ train['hour'] < 6, 'day_time'] = 1\n",
    "train.loc[(train['hour'] >=6) & (train['hour'] <= 11), 'day_time'] = 2\n",
    "train.loc[(train['hour'] >= 12) & (train['hour'] <= 17), 'day_time'] = 3\n",
    "train.loc[(train['hour'] > 18) , 'day_time'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a3f073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#more time related features\n",
    "\n",
    "train['srch_for_date'] = train['date_time']  + pd.to_timedelta(train['srch_booking_window'], unit='D')\n",
    "train[\"srch_for_month\"] = train[\"srch_for_date\"].dt.month\n",
    "train.loc[ train['srch_for_month'] <= 3, 'seasonality'] = 1\n",
    "train.loc[(train['srch_for_month'] > 3) & (train['srch_for_month'] <= 6), 'seasonality'] = 2\n",
    "train.loc[(train['srch_for_month'] > 6) & (train['srch_for_month'] <= 9), 'seasonality'] = 3\n",
    "train.loc[(train['srch_for_month'] > 9) , 'seasonality'] = 4\n",
    "\n",
    "train.loc[ train['month'] <= 3, 'qrtr'] = 1\n",
    "train.loc[(train['month'] > 3) & (train['month'] <= 6), 'qrtr'] = 2\n",
    "train.loc[(train['month'] > 6) & (train['month'] <= 9), 'qrtr'] = 3\n",
    "train.loc[(train['month'] > 9) , 'qrtr'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "570024cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling in missing values for prop_review_score and prop_starrating using average rating \n",
    "#based off similar priced hotels \n",
    "train['price_bin'] = pd.qcut(train['price_usd'], q=80, precision=0)\n",
    "train['mean_price_bin_star'] = train.groupby('price_bin')['prop_starrating'].transform('mean')\n",
    "train['mean_price_bin_review'] = train.groupby('price_bin')['prop_review_score'].transform('mean')\n",
    "train['prop_review_score'] = train['prop_review_score'].fillna(0)\n",
    "train.loc[train.prop_review_score == 0, \"prop_review_score\"] = train.mean_price_bin_review\n",
    "train.loc[train.prop_starrating == 0, \"prop_starrating\"] = train.mean_price_bin_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "690fd22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing price for hotels with other hotels in the same search\n",
    "\n",
    "train['max_price'] = train.groupby('srch_id')['price_usd'].transform('max') \n",
    "train['min_price'] = train.groupby('srch_id')['price_usd'].transform('min') \n",
    "train['mean_price'] = train.groupby('srch_id')['price_usd'].transform('mean') \n",
    "train['diff_max_price'] =(train['max_price'] -train['price_usd']) / train['price_usd']\n",
    "train['diff_min_price'] = (train['min_price'] - train['price_usd'])/ train['price_usd']\n",
    "train['diff_min_price'] = train['diff_min_price'].replace(np.nan, 0)\n",
    "train['diff_mean_price'] = (train['mean_price'] - train['price_usd']) / train['price_usd']\n",
    "train['price_review_value'] =  train['prop_review_score'] /train['mean_price_bin_review'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b099bb26",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-6a465437114b>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_calcs['hotel_avg_children'] = train_calcs.groupby('prop_id')['srch_children_count'].transform('mean')\n",
      "<ipython-input-32-6a465437114b>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_calcs['hotel_avg_adult'] = train_calcs.groupby('prop_id')['srch_adults_count'].transform('mean')\n",
      "<ipython-input-32-6a465437114b>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_calcs['hotel_avg_stay'] = train_calcs.groupby('prop_id')['srch_length_of_stay'].transform('mean')\n",
      "<ipython-input-32-6a465437114b>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_calcs['hotel_avg_room_count'] = train_calcs.groupby('prop_id')['srch_room_count'].transform('mean')\n",
      "<ipython-input-32-6a465437114b>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_calcs['bought'] = train_calcs.groupby('prop_id')['booking_bool'].transform('sum')\n"
     ]
    }
   ],
   "source": [
    "# getting actual click and booking statistics for each hotel & if there was a booking - how many adults,children,rooms\n",
    "\n",
    "train['hotel_show_prob'] =  train.groupby('prop_id')['prop_id'].transform('count') / (train.srch_id.unique()).size\n",
    "train_calcs = train[train.booking_bool == 1]\n",
    "train_calcs['hotel_avg_children'] = train_calcs.groupby('prop_id')['srch_children_count'].transform('mean') \n",
    "train_calcs['hotel_avg_adult'] = train_calcs.groupby('prop_id')['srch_adults_count'].transform('mean') \n",
    "train_calcs['hotel_avg_stay'] = train_calcs.groupby('prop_id')['srch_length_of_stay'].transform('mean') \n",
    "train_calcs['hotel_avg_room_count'] = train_calcs.groupby('prop_id')['srch_room_count'].transform('mean') \n",
    "train_calcs['bought'] = train_calcs.groupby('prop_id')['booking_bool'].transform('sum') \n",
    "train_calcs = train_calcs[['prop_id','hotel_avg_children', 'hotel_avg_adult', 'hotel_avg_stay','hotel_avg_room_count','bought']]\n",
    "\n",
    "#pd.crosstab(train.hotel_click_prob, train.prop_id, dropna=False)\n",
    "train_calcs = train_calcs.drop_duplicates(subset=['prop_id'])\n",
    "\n",
    "train['hotel_buy_prob'] = train.groupby('prop_id')['booking_bool'].transform('sum') / train.groupby('prop_id')['booking_bool'].transform('count')\n",
    "train['hotel_click_prob'] = train.groupby('prop_id')['click_bool'].transform('sum') / train.groupby('prop_id')['click_bool'].transform('count')\n",
    "train['hotel_qrtr_buy_prob'] = train.groupby(['qrtr','prop_id'])['booking_bool'].transform('sum') / train.groupby(['qrtr','prop_id'])['booking_bool'].transform('count')\n",
    "train['hotel_qrtr_click_prob'] = train.groupby(['qrtr','prop_id'])['click_bool'].transform('sum') / train.groupby(['qrtr','prop_id'])['click_bool'].transform('count')\n",
    "train['hotel_srch_sesn_buy_prob'] = train.groupby(['seasonality','prop_id'])['booking_bool'].transform('sum') / train.groupby(['seasonality','prop_id'])['booking_bool'].transform('count')\n",
    "train['hotel_srch_sesn_click_prob'] = train.groupby(['seasonality','prop_id'])['click_bool'].transform('sum') / train.groupby(['seasonality','prop_id'])['click_bool'].transform('count')\n",
    "\n",
    "\n",
    "hotel_click_stats = train[['prop_id', 'hotel_buy_prob','hotel_click_prob', 'hotel_qrtr_click_prob', 'hotel_qrtr_buy_prob', 'hotel_srch_sesn_buy_prob','hotel_srch_sesn_click_prob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2706bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## balancing the dataset - at first balanced it 50:50 but now balancing it 33:66\n",
    "df = train[train.outcome == 1]\n",
    "df1 = train[train.outcome == 0]\n",
    "df1 = df1.sample(n=len(df)*2)\n",
    "\n",
    "frames = [df, df1]\n",
    "\n",
    "train_reduced = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef661e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "### merging hotel specific cals to main dataset \n",
    "train_reduced = train_reduced.merge(train_calcs, left_on=['prop_id'], right_on=['prop_id'], how='left')\n",
    "train_reduced['hotel_avg_children'] = train_reduced['hotel_avg_children'].replace(np.nan, .367)\n",
    "train_reduced['hotel_avg_adult'] = train_reduced['hotel_avg_adult'].replace(np.nan, 1.95)\n",
    "train_reduced['hotel_avg_stay'] = train_reduced['hotel_avg_stay'].replace(np.nan, 2.09)\n",
    "train_reduced['hotel_avg_room_count'] = train_reduced['hotel_avg_room_count'].replace(np.nan, 1.13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e724157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>...</th>\n",
       "      <th>hotel_click_prob</th>\n",
       "      <th>hotel_qrtr_buy_prob</th>\n",
       "      <th>hotel_qrtr_click_prob</th>\n",
       "      <th>hotel_srch_sesn_buy_prob</th>\n",
       "      <th>hotel_srch_sesn_click_prob</th>\n",
       "      <th>hotel_avg_children</th>\n",
       "      <th>hotel_avg_adult</th>\n",
       "      <th>hotel_avg_stay</th>\n",
       "      <th>hotel_avg_room_count</th>\n",
       "      <th>bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>68914</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034305</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.046083</td>\n",
       "      <td>0.038278</td>\n",
       "      <td>0.047847</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>2.058824</td>\n",
       "      <td>1.235294</td>\n",
       "      <td>1.176471</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2012-12-31 08:59:22</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>139893</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>0.036697</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2013-06-05 12:27:51</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>104251</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2013-03-20 17:50:44</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>27669</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035897</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2013-02-25 08:39:33</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>20499</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665083</th>\n",
       "      <td>34448</td>\n",
       "      <td>2013-06-17 04:18:12</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>42782</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665084</th>\n",
       "      <td>159513</td>\n",
       "      <td>2013-02-25 20:22:45</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>74754</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014663</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.015584</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>2.111111</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665085</th>\n",
       "      <td>225537</td>\n",
       "      <td>2013-02-25 07:28:37</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>26016</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665086</th>\n",
       "      <td>149996</td>\n",
       "      <td>2012-12-17 19:19:29</td>\n",
       "      <td>18</td>\n",
       "      <td>129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>15503</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.367000</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665087</th>\n",
       "      <td>94580</td>\n",
       "      <td>2013-05-14 17:27:12</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>11332</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.367000</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>665088 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        srch_id           date_time  site_id  visitor_location_country_id  \\\n",
       "0             1 2013-04-04 08:32:15       12                          187   \n",
       "1             4 2012-12-31 08:59:22        5                          219   \n",
       "2             6 2013-06-05 12:27:51       14                          100   \n",
       "3             8 2013-03-20 17:50:44        5                          219   \n",
       "4            11 2013-02-25 08:39:33        5                          219   \n",
       "...         ...                 ...      ...                          ...   \n",
       "665083    34448 2013-06-17 04:18:12        5                          219   \n",
       "665084   159513 2013-02-25 20:22:45        5                          219   \n",
       "665085   225537 2013-02-25 07:28:37        5                          219   \n",
       "665086   149996 2012-12-17 19:19:29       18                          129   \n",
       "665087    94580 2013-05-14 17:27:12        2                           56   \n",
       "\n",
       "        visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id  \\\n",
       "0                           NaN                   NaN              219   \n",
       "1                           NaN                   NaN              219   \n",
       "2                           NaN                   NaN              100   \n",
       "3                           NaN                   NaN              219   \n",
       "4                           NaN                   NaN              219   \n",
       "...                         ...                   ...              ...   \n",
       "665083                      NaN                   NaN              219   \n",
       "665084                      NaN                   NaN              219   \n",
       "665085                      NaN                   NaN              219   \n",
       "665086                      NaN                   NaN               99   \n",
       "665087                      NaN                   NaN               55   \n",
       "\n",
       "        prop_id  prop_starrating  prop_review_score  ...  hotel_click_prob  \\\n",
       "0         68914              2.0                3.0  ...          0.034305   \n",
       "1        139893              2.0                3.0  ...          0.033520   \n",
       "2        104251              3.0                4.0  ...          0.045455   \n",
       "3         27669              3.0                3.5  ...          0.035897   \n",
       "4         20499              2.0                3.5  ...          0.030612   \n",
       "...         ...              ...                ...  ...               ...   \n",
       "665083    42782              3.0                4.5  ...          0.040000   \n",
       "665084    74754              4.0                4.5  ...          0.014663   \n",
       "665085    26016              3.0                4.0  ...          0.013216   \n",
       "665086    15503              3.0                3.5  ...          0.000000   \n",
       "665087    11332              4.0                5.0  ...          0.000000   \n",
       "\n",
       "        hotel_qrtr_buy_prob  hotel_qrtr_click_prob  hotel_srch_sesn_buy_prob  \\\n",
       "0                  0.032258               0.046083                  0.038278   \n",
       "1                  0.000000               0.035088                  0.027523   \n",
       "2                  0.071429               0.071429                  0.090909   \n",
       "3                  0.049383               0.061728                  0.040541   \n",
       "4                  0.000000               0.026316                  0.026316   \n",
       "...                     ...                    ...                       ...   \n",
       "665083             0.090909               0.090909                  0.111111   \n",
       "665084             0.005263               0.010526                  0.007792   \n",
       "665085             0.010101               0.030303                  0.014085   \n",
       "665086             0.000000               0.000000                  0.000000   \n",
       "665087             0.000000               0.000000                  0.000000   \n",
       "\n",
       "        hotel_srch_sesn_click_prob  hotel_avg_children  hotel_avg_adult  \\\n",
       "0                         0.047847            0.176471         2.058824   \n",
       "1                         0.036697            0.285714         2.142857   \n",
       "2                         0.090909            0.000000         2.000000   \n",
       "3                         0.040541            0.166667         1.666667   \n",
       "4                         0.052632            0.000000         2.000000   \n",
       "...                            ...                 ...              ...   \n",
       "665083                    0.111111            0.000000         1.000000   \n",
       "665084                    0.015584            0.555556         2.111111   \n",
       "665085                    0.028169            0.000000         2.000000   \n",
       "665086                    0.000000            0.367000         1.950000   \n",
       "665087                    0.000000            0.367000         1.950000   \n",
       "\n",
       "        hotel_avg_stay  hotel_avg_room_count  bought  \n",
       "0             1.235294              1.176471    17.0  \n",
       "1             1.285714              1.285714     7.0  \n",
       "2             1.000000              1.000000     1.0  \n",
       "3             1.833333              1.000000     6.0  \n",
       "4             1.000000              1.000000     1.0  \n",
       "...                ...                   ...     ...  \n",
       "665083        1.000000              1.000000     1.0  \n",
       "665084        2.666667              1.000000     9.0  \n",
       "665085        2.000000              1.000000     1.0  \n",
       "665086        2.090000              1.130000     NaN  \n",
       "665087        2.090000              1.130000     NaN  \n",
       "\n",
       "[665088 rows x 63 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reduced # 63 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "493e98f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropped price bin\n",
    "train_reduced = train_reduced.drop(['price_bin'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ac4da8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "srch_id                         0.00000\n",
       "date_time                       0.00000\n",
       "site_id                         0.00000\n",
       "visitor_location_country_id     0.00000\n",
       "visitor_hist_starrating        94.93646\n",
       "                                 ...   \n",
       "hotel_avg_children              0.00000\n",
       "hotel_avg_adult                 0.00000\n",
       "hotel_avg_stay                  0.00000\n",
       "hotel_avg_room_count            0.00000\n",
       "bought                         20.46857\n",
       "Length: 62, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking %% of nulls in the dataset \n",
    "train_reduced.isnull().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e7e68ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "##droppping columns not needed \n",
    "\n",
    "to_drop = ['srch_id','site_id', 'date_time', 'visitor_location_country_id', 'prop_country_id', 'prop_id', 'prop_brand_bool', 'orig_destination_distance', 'click_bool', 'booking_bool', 'srch_destination_id', 'position', 'prop_location_score2'\n",
    "          ,'gross_bookings_usd', 'price_usd', 'max_price','min_price', 'mean_price', 'mean_price_bin_review','mean_price_bin_star', 'bought', 'weekday', 'week_of_year', 'hour', 'time_epoch'] \n",
    "#'room_count_grt_1_flag',\n",
    "train1 = train_reduced.drop(to_drop,  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30d2b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: delete!!\n",
    "\n",
    "to_drop = ['site_id', 'date_time', 'visitor_location_country_id', 'prop_country_id', 'prop_id', 'prop_brand_bool', 'orig_destination_distance', 'click_bool', 'booking_bool', 'srch_destination_id', 'prop_location_score2'\n",
    "          ,'gross_bookings_usd', 'price_usd', 'max_price','min_price', 'mean_price', 'mean_price_bin_review','mean_price_bin_star', 'bought', 'weekday', 'week_of_year', 'hour', 'time_epoch'] \n",
    "#'room_count_grt_1_flag',\n",
    "train1 = train_reduced.drop(to_drop,  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f13d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train1.head() # 39 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e948710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec704d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##changing nan or null values to 0\n",
    "train1.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "train1=train1.dropna(axis=1,how=\"any\")\n",
    "#msn.bar(train1,figsize=(18,3), color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4915a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ordering columns and selecting predictors + outcome\n",
    "train1 = train1[['prop_starrating', 'prop_location_score1','prop_log_historical_price','promotion_flag','srch_length_of_stay','srch_booking_window','srch_adults_count','srch_children_count','srch_room_count','srch_saturday_night_bool', 'hotel_click_prob', 'hotel_buy_prob','diff_max_price','diff_min_price','diff_mean_price','hotel_show_prob', 'prop_review_score','price_review_value', 'hotel_avg_children','hotel_avg_adult','hotel_avg_stay','hotel_avg_room_count','random_bool','qrtr','hotel_qrtr_click_prob', 'hotel_qrtr_buy_prob', 'hotel_srch_sesn_buy_prob','hotel_srch_sesn_click_prob','outcome']]\n",
    "#train1 = train1[['srch_id', 'position', 'prop_starrating', 'prop_location_score1','prop_log_historical_price','promotion_flag','srch_length_of_stay','srch_booking_window','srch_adults_count','srch_children_count','srch_room_count','srch_saturday_night_bool', 'hotel_click_prob', 'hotel_buy_prob','diff_max_price','diff_min_price','diff_mean_price','hotel_show_prob', 'prop_review_score','price_review_value', 'hotel_avg_children','hotel_avg_adult','hotel_avg_stay','hotel_avg_room_count','random_bool','qrtr','hotel_qrtr_click_prob', 'hotel_qrtr_buy_prob', 'hotel_srch_sesn_buy_prob','hotel_srch_sesn_click_prob','outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffc12e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train1.head() # 31 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f19cc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting dataset \n",
    "X = train1.iloc[:, :-1].values\n",
    "y = train1.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d38f274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579fbcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b8c31485",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##list of models we can use, can take along time to do them all so try one or two at a time. \n",
    "\n",
    "models_list=[\n",
    "    LogisticRegression(),\n",
    "  #  Lasso(),\n",
    "   # RandomForestClassifier(criterion='entropy', min_samples_leaf=60,\n",
    "             #          min_samples_split=4, random_state=16),\n",
    "    #GradientBoostingClassifier(),\n",
    "    lgb.LGBMClassifier(),\n",
    "   # LinearSVC(random_state=42, C=0.01),\n",
    "    #xgb.XGBRegressor(objective=\"reg:linear\", random_state=42)   \n",
    "  #  xgb.XGBClassifier(objective=\"binary:logistic\", random_state=0, eval_metric=\"auc\", n_estimators=100, max_depth=6,learning_rate=0.1), \n",
    " #   xgb.XGBClassifier(objective=\"binary:logistic\", random_state=0, eval_metric=\"auc\", n_estimators=100, max_depth=6,learning_rate=0.05), #better. \n",
    "  #  xgb.XGBClassifier(objective=\"binary:logistic\", random_state=0, eval_metric=\"auc\", n_estimators=100, max_depth=6,learning_rate=0.01), \n",
    "    #  \"multi:softprob\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c2cb071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "model score: 0.757\n",
      "LGBMClassifier()\n",
      "model score: 0.807\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "#loop thorugh list of models to use. Train them and give an acuracy score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "l=[]\n",
    "for model in models_list:\n",
    "    #clf=clf_models(model)\n",
    "    print(model)\n",
    "    fit_model=model.fit(X_train, y_train)\n",
    "    score=model.score(X_test, y_test)\n",
    "    print(\"model score: %.3f\" % score)\n",
    "    l.append([model,'clf', score, X_test, y_test])\n",
    "    #print(clf)\n",
    "    #scores = -1 * cross_val_score(clf, X, y,cv=5,scoring='neg_mean_absolute_error')\n",
    "    #print(\"MAE scores:\\n\", scores.mean(), scores.sum(), scores.min())\n",
    "    \n",
    "#print(l[3][4])\n",
    "#print(l[2][3])\n",
    "#print(l[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3fbf0932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 0 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using the lost of models we select on and use it to predict the test data with an output \n",
    "\n",
    "y_pred=l[1][0].predict(X_test)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e457d0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>result</th>\n",
       "      <th>perdicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.95</td>\n",
       "      <td>4.58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.43</td>\n",
       "      <td>5.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.039370</td>\n",
       "      <td>0.039370</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>0.039604</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>5.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3    4     5    6    7    8    9  ...        20  \\\n",
       "0  4.0  1.10  0.00  0.0  3.0  24.0  2.0  1.0  1.0  0.0  ...  2.090000   \n",
       "1  3.0  1.95  4.58  1.0  1.0  12.0  2.0  0.0  1.0  1.0  ...  2.090000   \n",
       "2  4.0  4.43  5.03  0.0  8.0  55.0  2.0  0.0  1.0  0.0  ...  2.090000   \n",
       "3  4.0  3.04  0.00  0.0  1.0   5.0  1.0  0.0  1.0  1.0  ...  1.142857   \n",
       "4  4.0  2.20  5.49  0.0  4.0  65.0  4.0  0.0  1.0  0.0  ...  1.888889   \n",
       "\n",
       "         21   22   23        24        25        26        27  result  \\\n",
       "0  1.130000  0.0  2.0  0.000000  0.000000  0.000000  0.000000       0   \n",
       "1  1.130000  1.0  2.0  0.125000  0.000000  0.000000  0.100000       1   \n",
       "2  1.130000  1.0  2.0  0.250000  0.000000  0.000000  0.285714       1   \n",
       "3  1.142857  0.0  2.0  0.039370  0.039370  0.029703  0.039604       0   \n",
       "4  1.222222  0.0  2.0  0.092105  0.026316  0.045455  0.181818       0   \n",
       "\n",
       "   perdicted  \n",
       "0          0  \n",
       "1          1  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# writing the results to a dataframe to analyse seperatly if needed ( ie how many false negatives, check values ect)\n",
    "\n",
    "result = pd.DataFrame(y_test, columns=['actual'])\n",
    "predicted= pd.DataFrame(y_pred, columns=['predicted'])\n",
    "\n",
    "df = pd.DataFrame(X_test)\n",
    "df['result'] = result\n",
    "df['perdicted'] = predicted\n",
    "df.to_csv('results2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3da206",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### pred \n",
    "to_pred=pd.read_csv(\"../test_set_VU_DM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7530e21d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5b6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f23e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import competition dataset \n",
    "\n",
    "#to_pred=pd.read_csv(\"../test_set_VU_DM.csv\")\n",
    "#test=pd.read_csv(\"test_set_VU_DM.csv\")\n",
    "\n",
    "to_drop= ['comp1_rate',\n",
    "'comp1_inv',\n",
    "'comp1_rate_percent_diff',\n",
    "'comp2_rate',\n",
    "'comp2_inv',\n",
    "'comp2_rate_percent_diff',\n",
    "'comp3_rate',\n",
    "'comp3_inv',\n",
    "'comp3_rate_percent_diff',\n",
    "'comp4_rate',\n",
    "'comp4_inv',\n",
    "'comp4_rate_percent_diff',\n",
    "'comp5_rate',\n",
    "'comp5_inv',\n",
    "'comp5_rate_percent_diff',\n",
    "'comp6_rate',\n",
    "'comp6_inv',\n",
    "'comp6_rate_percent_diff',\n",
    "'comp7_rate',\n",
    "'comp7_inv',\n",
    "'comp7_rate_percent_diff',\n",
    "'comp8_rate',\n",
    "'comp8_inv',\n",
    "'comp8_rate_percent_diff'\n",
    "\n",
    "]\n",
    "\n",
    "#train['outcome'] = pd.Series(train['booking_bool']> 0, 500 + train['position'] , train['click_bool']> 0, 100 +train['position'] , 0 + train['position'] )\n",
    "\n",
    "\n",
    "\n",
    "to_pred = to_pred.drop(to_drop,  axis=1)#.sample(frac=0.2, replace=True, random_state=1)\n",
    "#test_reduced  = test.iloc[: , :N].sample(frac=0.33, replace=True, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9383e32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d608f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating same features as test data\n",
    "\n",
    "to_pred['date_time'] = pd.to_datetime(to_pred['date_time'], errors='coerce')\n",
    "to_pred[\"weekday\"] = to_pred[\"date_time\"].dt.weekday\n",
    "to_pred[\"week_of_year\"] = to_pred[\"date_time\"].dt.week\n",
    "to_pred[\"month\"] = to_pred[\"date_time\"].dt.month\n",
    "to_pred[\"hour\"] = to_pred[\"date_time\"].dt.hour\n",
    "to_pred[\"time_epoch\"] = to_pred[\"date_time\"].astype('int64')//1e9\n",
    "to_pred[\"time_epoch\"] = to_pred[\"date_time\"].astype('int64')//1e9\n",
    "to_pred.loc[ to_pred['hour'] < 6, 'day_time'] = 1\n",
    "to_pred.loc[(to_pred['hour'] >=6) & (to_pred['hour'] <= 11), 'day_time'] = 2\n",
    "to_pred.loc[(to_pred['hour'] >= 12) & (to_pred['hour'] <= 17), 'day_time'] = 3\n",
    "to_pred.loc[(to_pred['hour'] > 18) , 'day_time'] = 4\n",
    "\n",
    "##################\n",
    "\n",
    "to_pred['srch_for_date'] = to_pred['date_time']  + pd.to_timedelta(to_pred['srch_booking_window'], unit='D')\n",
    "to_pred[\"srch_for_month\"] = to_pred[\"srch_for_date\"].dt.month\n",
    "\n",
    "#train['srch_for_date'] = train['date_time']  + pd.to_timedelta(train['srch_booking_window'], unit='D')\n",
    "#train[\"srch_for_month\"] = train[\"srch_for_date\"].dt.month\n",
    "to_pred.loc[ to_pred['srch_for_month'] <= 3, 'seasonality'] = 1\n",
    "to_pred.loc[(to_pred['srch_for_month'] > 3) & (to_pred['srch_for_month'] <= 6), 'seasonality'] = 2\n",
    "to_pred.loc[(to_pred['srch_for_month'] > 6) & (to_pred['srch_for_month'] <= 9), 'seasonality'] = 3\n",
    "to_pred.loc[(to_pred['srch_for_month'] > 9) , 'seasonality'] = 4\n",
    "\n",
    "to_pred.loc[ to_pred['month'] <= 3, 'qrtr'] = 1\n",
    "to_pred.loc[(to_pred['month'] > 3) & (to_pred['month'] <= 6), 'qrtr'] = 2\n",
    "to_pred.loc[(to_pred['month'] > 6) & (to_pred['month'] <= 9), 'qrtr'] = 3\n",
    "to_pred.loc[(to_pred['month'] > 9) , 'qrtr'] = 4\n",
    "\n",
    "####################\n",
    "\n",
    "to_pred['price_bin'] = pd.qcut(to_pred['price_usd'], q=80, precision=0)\n",
    "to_pred['mean_price_bin_star'] = to_pred.groupby('price_bin')['prop_starrating'].transform('mean')\n",
    "to_pred['mean_price_bin_review'] = to_pred.groupby('price_bin')['prop_review_score'].transform('mean')\n",
    "to_pred['prop_review_score'] = to_pred['prop_review_score'].fillna(0)\n",
    "to_pred.loc[to_pred.prop_review_score == 0, \"prop_review_score\"] = to_pred.mean_price_bin_review\n",
    "to_pred.loc[to_pred.prop_starrating == 0, \"prop_starrating\"] = to_pred.mean_price_bin_star\n",
    "\n",
    "##################\n",
    "\n",
    "to_pred['max_price'] = to_pred.groupby('srch_id')['price_usd'].transform('max') \n",
    "to_pred['min_price'] = to_pred.groupby('srch_id')['price_usd'].transform('min') \n",
    "to_pred['mean_price'] = to_pred.groupby('srch_id')['price_usd'].transform('mean') \n",
    "to_pred['diff_max_price'] =(to_pred['max_price'] -to_pred['price_usd']) / to_pred['price_usd']\n",
    "to_pred['diff_min_price'] = (to_pred['min_price'] - to_pred['price_usd'])/ to_pred['price_usd']\n",
    "to_pred['diff_min_price'] = to_pred['diff_min_price'].replace(np.nan, 0)\n",
    "to_pred['diff_mean_price'] = (to_pred['mean_price'] - to_pred['price_usd']) / to_pred['price_usd']\n",
    "to_pred['price_review_value'] =  to_pred['prop_review_score'] /to_pred['mean_price_bin_review'] \n",
    "\n",
    "#################\n",
    "\n",
    "to_pred['hotel_show_prob'] =  to_pred.groupby('prop_id')['prop_id'].transform('count') / (to_pred.srch_id.unique()).size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b577ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### mergeing hotel specific stats from test dataset \n",
    "\n",
    "to_pred_reduced = to_pred.merge(train_calcs, left_on=['prop_id'], right_on=['prop_id'], how='left')\n",
    "hotel_click_stats = hotel_click_stats.drop_duplicates(subset=['prop_id'])\n",
    "to_pred_reduced = to_pred_reduced.merge(hotel_click_stats, left_on=['prop_id'], right_on=['prop_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130107f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#train_reduced = train_reduced.merge(train_clacs, on='prop_id', how='right', suffixes=('_1', '_2'))\n",
    "#to_pred_reduced  = pd.concat([to_pred_reduced.set_index('prop_id'),train_calcs.set_index('prop_id')], axis=1, join='outer').reset_index()\n",
    "#to_pred_reduced2  = pd.concat([to_pred_reduced.set_index('prop_id'),hotel_click_stats.set_index('prop_id')], axis=1, join='outer').reset_index()\n",
    "to_pred_reduced['hotel_avg_children'] = to_pred_reduced['hotel_avg_children'].replace(np.nan, .367)\n",
    "to_pred_reduced['hotel_avg_adult'] = to_pred_reduced['hotel_avg_adult'].replace(np.nan, 1.95)\n",
    "to_pred_reduced['hotel_avg_stay'] = to_pred_reduced['hotel_avg_stay'].replace(np.nan, 2.09)\n",
    "to_pred_reduced['hotel_avg_room_count'] = to_pred_reduced['hotel_avg_room_count'].replace(np.nan, 1.13)\n",
    "to_pred_reduced[['hotel_click_prob', 'hotel_buy_prob']] = to_pred_reduced[['hotel_click_prob', 'hotel_buy_prob']].fillna(0)\n",
    "\n",
    "\n",
    "#train_reduced.to_csv('hotel_calcs2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4761e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pred_reduced.isnull().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f6cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###droppping unused columns \n",
    "\n",
    "to_drop = ['site_id', 'date_time', 'visitor_location_country_id', 'prop_country_id','price_bin', 'prop_brand_bool', 'orig_destination_distance', 'srch_destination_id', 'prop_location_score2'\n",
    "          ,'price_usd','price_bin', 'max_price', 'srch_query_affinity_score','visitor_hist_starrating', 'visitor_hist_adr_usd', 'min_price', 'mean_price', 'mean_price_bin_review','mean_price_bin_star', 'bought',  'weekday', 'week_of_year', 'hour', 'time_epoch'] \n",
    "\n",
    "to_pred1 = to_pred_reduced.drop(to_drop,  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e47cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "msn.bar(to_pred1,figsize=(18,3), color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08568c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing nulls and nans\n",
    "\n",
    "to_pred1.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "to_pred1[['hotel_qrtr_click_prob', 'hotel_qrtr_buy_prob', 'hotel_srch_sesn_buy_prob', 'hotel_srch_sesn_click_prob']] = to_pred1[['hotel_qrtr_click_prob', 'hotel_qrtr_buy_prob', 'hotel_srch_sesn_buy_prob', 'hotel_srch_sesn_click_prob']].replace(np.nan, 0)\n",
    "\n",
    "to_pred1=to_pred1.dropna(axis=1,how=\"any\")\n",
    "msn.bar(to_pred1,figsize=(18,3), color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ordering df and selecting predictors\n",
    "to_pred1 = to_pred1[['prop_starrating', 'prop_location_score1','prop_log_historical_price','promotion_flag','srch_length_of_stay','srch_booking_window','srch_adults_count','srch_children_count','srch_room_count','srch_saturday_night_bool', 'hotel_click_prob', 'hotel_buy_prob','diff_max_price','diff_min_price','diff_mean_price','hotel_show_prob', 'prop_review_score','price_review_value', 'hotel_avg_children','hotel_avg_adult','hotel_avg_stay','hotel_avg_room_count','random_bool','qrtr','hotel_qrtr_click_prob', 'hotel_qrtr_buy_prob', 'hotel_srch_sesn_buy_prob','hotel_srch_sesn_click_prob', 'srch_id', 'prop_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764d316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pred1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd65833",
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving serch_id and prod_id for use in submission file \n",
    "\n",
    "ids = to_pred1[['srch_id', 'prop_id']]\n",
    "\n",
    "to_drop = ['srch_id','prop_id']\n",
    "\n",
    "to_pred1 = to_pred1.drop(to_drop,  axis=1)\n",
    "\n",
    "###### perdicitng outcome using model\n",
    "\n",
    "y_pred=l[1][0].predict(to_pred1)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246e97f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###creating submission file\n",
    "\n",
    "predicted= pd.DataFrame(y_pred, columns=['predicted'])\n",
    "\n",
    "df = pd.DataFrame(to_pred1)\n",
    "\n",
    "df['perdicted'] = predicted\n",
    "\n",
    "df[['srch_id', 'prop_id']] = ids[['srch_id', 'prop_id']]\n",
    "\n",
    "df = df[['srch_id', 'prop_id', 'perdicted','hotel_buy_prob']]\n",
    "\n",
    "##ordering submission file \n",
    "\n",
    "\n",
    "df = df.sort_values(['srch_id', 'perdicted', 'hotel_buy_prob'],\n",
    "              ascending = [True, False,False])\n",
    "df = df.drop(['perdicted', 'hotel_buy_prob'], axis = 1)\n",
    "df.to_csv('submission.csv', index=False)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b2697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902a9e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
